---
title: "Halloween candy: analysis report"
output: html_notebook
date: 2023-06-15
author: Naomi Penfold
---

# Introduction

This report is about candy preferences based on data from surveying people around Halloween (including both those who go trick-or-treating and those who do not). The data includes information about the rater (such as age, gender and country (as specified by the rater), whether or not they go out trick or treating, their ratings of named items (in terms of JOY, MEH, and DESPAIR), as well as their answers to some additional questions. More information about the data is available [here](https://www.scq.ubc.ca/so-much-candy-data-seriously/). 

This report was prepared as an output for the Codeclan "Dirty Data" project week, and details how the data from 2015, 2016 and 2017 were prepared for analysis as well as the results of the analyses, through the following sections:

* 1: [Planning](#plan) how to prepare data for analysis
* 2: [Preparing](#prepare) raw data for joining years to create one dataset
* 3: [Cleaning](#clean) joined data ready for analysis
* 4: [Analysis](#analyse)
* 5: [Reflections](#reflect)

## About the code in this notebook

To run the code in the Analysis section, first run the `data_cleaning_scripts/cleaning.R`. This produces the `clean_data/candy_ratings_allyears_clean.csv` with the tidied data prepared for analysis.

Running the code in the **Preparing** and **Cleaning** sections of this notebook creates several new objects in the R environment. None of these are needed for the subsequent analysis. They are included here to demonstrate the decisions taken in order to produce the `cleaning.R` script.

Running the code in the **Analysis** section creates:

* `candy_ratings_analysis` is the loaded clean data
* `candy_raters_analysis` is a subset of this clean data that includes the information about each individual rater (without their ratings)
* `candy_ratings_analysis_num` includes an additional column that encodes the ratings numerically (JOY as +1, MEH as 0, DESPAIR as -1) and is used when calculating popularity of candy items in various analyses

In addition, code in the **Reflections** section produces a vector called `candy_items`, which lists all the candy items included in the cleaned data (note: I have excluded multiple items rated in the survey, where I have deemed them not to be "Candy"). This is an artefact that could be used to improve the `cleaning.R` script (not done within this project).


```{r, message = FALSE}
library(tidyverse)
library(readxl)
library(here)
```

# 1: Plan for how to prepare data for analysis {#plan}

## Load raw data

```{r, message = FALSE}
excel_sheets(here("raw_data/boing-boing-candy-2015.xlsx"))
excel_sheets(here("raw_data/boing-boing-candy-2016.xlsx"))
excel_sheets(here("raw_data/boing-boing-candy-2017.xlsx"))
```

Each excel has only one sheet, each excel file is a dataset for one year. 

Read these in:
```{r, message = FALSE}
x2015 <- read_excel(here("raw_data/boing-boing-candy-2015.xlsx"), sheet = "Form Responses 1")
x2016 <- read_excel(here("raw_data/boing-boing-candy-2016.xlsx"), sheet = "Form Responses 1")
x2017 <- read_excel(here("raw_data/boing-boing-candy-2017.xlsx"), sheet = "responses (2) (1).csv")
```

## Review analysis questions

Which variables do we need to answer the requested analysis questions? We need:

* All candy ratings (1 rating of 1 candy bar by 1 rater in 1 year = 1 observation)
* Age of rater, where available
* Whether or not the rater goes out trick or treating
* To be able to summarise count of ratings (joy, meh, despair) for each candy bar
* Gender of rater, where available
* To be able to filter for Starburst and count despair ratings
* To be able to convert ratings to +1, 0, -1 (new column) and sum across these 3
* To be able to group by year
* To be able to group by country

## Plan approach for joining data (and making it 'tidy' long format)

Step 1: Make tidy data

  * We want variables: rater_info (ToT_activity, age, gender, country), rating_year, type of candy bar <chr>, rating (joy, meh, despair) 
  * Make sure variables are in same (and desired) data type in all 3 dfs
  * add a column for year in each dataset
  * add column with NAs for any of the above variables where data does not exist in that year's df 

Step 2: Join the tidy dataframes (append rows)

Aim: I want to make one combined df. that looks like the following, whereby 1 rating of 1 candy item by 1 rater in 1 year = 1 observation:

| year <dttm> | id <int> | age <int> | gender <chr> | country <chr> | goes_trick_or_treating <chr or lgl> | candy_item <chr> | rating <chr>  | [And later: rating_value <dbl>] |
|----|----|----|----|----|----|----|----|----|
| 2015 | 5058 | 23 | Male | USA | TRUE | Twix | JOY | 1 |
| 2016 | 1123 | 36 | Female | Canada | FALSE | Twix | DESPAIR | -1 |
| 2016 | 1123 | 36 | Female | Canada | FALSE | Trail mix | MEH | 0 |

Once joined, I can deal with cleaning data values, such as inconsistent candy bar names and countries.

# 2: Preparing year data for joining {#prepare}

Here, I have inspected the variables within each year's dataset, and decided what to remove, what to keep and how to keep it, to achieve the above aim of combined tidy data.

## 2015 data

Variables to keep/convert:

| Column # | Current variable name <type> | Action required to make tidy data |
| ----- | ----- | ----- |
| 1 | `Timestamp` <dttm> | Convert to `year` <dttm (YYYY)> |
| 2 | `How old are you?` <chr> | Convert to `age` <int> |
| 3 | `Are you going actually going trick or treating yourself?` <chr> |  Convert to `goes_trick_or_treating` <chr or lgl> |
| 4-17,19-22,24-25,29-32,35-37,39-40,42-44,46-55,57-81,83-89,91-92,96,114,115 | `Candy or other substance` <chr> | Remove non-candy items (see below) then make tidy -> `Candy_item` <chr> + `Rating` <chr> |
| 97,100-113,116-124 | Miscellaneous  | Remove |
| 98 | `Please list any items not included above that give you JOY.` | Extract answers --> new cols with JOY as value, and include in tidying step |
| 99 | `Please list any items not included above that give you DESPAIR.` | Extract answers --> new cols with DESPAIR as value, and include in tidying step |

Decisions on variables to keep/remove:

* Some are not candy (either obviously or by searching online), so removed:
  * Other food items, not candy: [34] `Healthy fruit`, [41] `Kale smoothie`, [56] `Minibags of chips` (crisps, not candy), [82] `Spotted Dick` (cake, not candy), [90] `Peanut butter jars` (nut butter, not candy), [94] `White bread`, [95] `Whole wheat anything`
  * Pharmaceuticals: [26] `[Generic Brand Acetaminophen]`, [93] `[Vicodin]`
  * other items, not food: [18] `Cash...`, [23] `Dental paraphenalia`, [27] `Glow sticks`, [28] `Broken glow stick`, [33] `Creepy Religious comics...`, [38] `Hugs...`, [45] `Lapel pins`
* Items kept in include candy that I recognise by name or have identified as candy by searching online, for example:
  * [63] `Pencils`, [88] `Peterson Brand sidewalk chalk`, [91] `Trail mix` - note decided to keep this in as it is a high sugar content snack.

```{r 2015_steps1:3}
# a tidier version of this code chunk is in cleaning.R script

# keep wanted columns, and put 98-99 (additional ratings) at end
x2015_subset <- x2015 %>% 
  select(1:17,19:22,24,25,29:32,35:37,39:40,42:44,46:55,57:81,83:89,91,92,96,114,115,98,99)

# tidy column names and some data
x2015_subset_converted_all <- x2015_subset %>% 
  # make an id column to retain unique identifier for each person
  mutate(id = c(1:5630), .before = "Timestamp") %>%
  # rename variables about the rater & rating year
  rename(age = "How old are you?",
          goes_trick_or_treating = "Are you going actually going trick or treating yourself?",
          year = "Timestamp",
          additional_joy = "Please list any items not included above that give you JOY.",
          additional_despair = "Please list any items not included above that give you DESPAIR.") %>%
  # recode some specific age values before converting to numeric (see "Coerced age data" below)
  mutate(age = case_when(
    id == 378 ~ "45",
    id == 792 ~ "37",
    id == 1210 ~ "43",
    id == 1571 ~ "46",
    id == 1629 ~ "40",
    id == 2207 ~ "37",
    id == 2934 ~ "50",
    id == 3384 ~ "27",
    id == 3626 ~ "50",
    id == 4798 ~ "42",
    id == 5624 ~ "50",
    .default = age)) %>% 
  mutate(age = as.integer(age),  # Note: this introduces NAs by coercion
         year = as.numeric(format(year, "%Y"))) %>% 
  # make empty columns for gender and country (missing in this year's dataset)
  mutate(gender = rep(NA_character_, nrow(x2015_subset)), .after = age) %>% 
  mutate(country = rep(NA_character_, nrow(x2015_subset)), .after = gender) %>% 
  # reformat id as YYYYxxxx to make unique when years combined
  mutate(id = (year*10000)+id, .before = year) %>% 
  filter(!id == 20151573) # remove 1 duplicate (found via 'coerced age data')

# Proceed without these additional joy/despair ratings:
x2015_subset_converted_sub <- x2015_subset_converted_all %>% 
  select(-c(additional_joy,additional_despair))

# 'tidy' subsetted data to long format with
# one column for candy items [7-85], one column for rating
# expect 5629 x 85 to become 
#   (5629 raters * 79 items) x 8 = 444,691 x 8
x2015_tidy <- x2015_subset_converted_sub %>% 
  pivot_longer(cols = -c(year, id, age, gender, country, goes_trick_or_treating),
               names_to = "candy_item",
               values_to = "rating")
```

The above code that is needed to generate the tidy version of 2015 data has been included in `cleaning.R` script; note I have removed the additional JOY and DESPAIR ratings contained within the free text answers, although these could be included in a later iteration to add more data.

#### Coerced age data

Converting age data from <chr> to numeric coerces some values into NAs, so I have inspected raw data to understand what I might be missing by doing this:

```{r}
# this code relies on output generated in earlier chunks: `x2015_subset_converted_sub` and `x2015`

# check for NAs in converted age column
x2015_id_na_age <- x2015_subset_converted_sub %>% 
  filter(is.na(age)) %>% # 285 rows
  # make vector of IDs to filter for to inspect raw data (with IDs)
  select(id) %>% 
  pull()
   
x2015_id_age_raw <- x2015 %>% 
  # add ids to raw data
  mutate(id = c(1:5630), .before = Timestamp) %>% 
  rename(age_raw = "How old are you?") %>% 
  # filter for ids with NA in converted age
  filter(id %in% x2015_id_na_age) %>% 
  select(id, age_raw) %>% # several NAs, filter out 
  filter(!is.na(age_raw)) # 85 rows
```

Inspecting these 85 answers, there are a few I will recode to include in dataset, the rest are not meaningful enough and can be coerced to NAs. 

To recode:

| id | age_raw | recode as age: |
|-----|-----|-----|
| 378 | "45, but the 8-year-old Huntress..." | 45 |
| 792 | "37 (I'm taking a child)" | 37 |
| 1210 | "Good Lord!  I'm 43!" | 43 |
| 1571 | "46:" | 46 |
| 1573 | "46:" | 46 |
| 1629 | "40. Deal with it." | 40 |
| 2207 | "37," | 37 |
| 2934 | "50 (despair)" | 50 |
| 3384 | "27^" | 27 |
| 3626 | "50, taking a 13 year old." | 50 |
| 4798 | "42 - I'm taking my kid" | 42 |
| 5624 | "50t" | 50 |

Notes:

* 1571 and 1573 are exactly the same - suspicious there may be duplicate entries. Checked full data for these IDs (see below) and decided to remove 1573 from the dataset, since it is a duplicate entry.
* Recode age values for the IDs as above (excluding 1573, to be removed) =  expect to end up with (285 - 11) = 274 NAs in final data.
* Cannot recode simply by removing punctuation or characters (e.g. "27^", "50t") because several use "+" to indicate a non-specific age (e.g. "30+").

```{r}
# recode these ages - reuse this code in cleaning script (as above)
x2015_id_age_raw %>% 
  mutate(age = case_when(
    id == 378 ~ "45",
    id == 792 ~ "37",
    id == 1210 ~ "43",
    id == 1571 ~ "46",
    id == 1629 ~ "40",
    id == 2207 ~ "37",
    id == 2934 ~ "50",
    id == 3384 ~ "27",
    id == 3626 ~ "50",
    id == 4798 ~ "42",
    id == 5624 ~ "50",
    .default = age_raw
  )) %>% 
  mutate(age_num = as.integer(age)) %>% 
  group_by(age_num) %>% 
  summarise(count = n()) # recoded 11 values, 74 NAs remaining
```


#### Additional data not yet in columns

Columns 98-99 in x2015 (raw data) are free text fields used to record additional items that are rated as JOY or DESPAIR, respectively, by the rater.

If time, I could add these additional data into the 2015 dataset before making it long format. For now, given the number of entries here (see below: 1000s additional rows to process), I will proceed without using this data, and thus discard it from the data to proceed with.

```{r}
# Create separate table for additional items rated as JOY or DESPAIR with person id
x2015_additional_ratings <- x2015_subset_converted_all %>% 
  select(id, additional_joy, additional_despair)
head(x2015_additional_ratings, n=10)

# see list of additional candy items rated JOY
x2015_additional_joy <- x2015_additional_ratings %>% 
  filter(!is.na(additional_joy)) %>% 
  select(id, additional_joy) #2436 rows

# see list of additional candy items rated DESPAIR
x2015_additional_despair <- x2015_additional_ratings %>% 
  filter(!is.na(additional_despair)) %>% 
  select(id, additional_despair) #1775 rows
```

#### Summary from tidying 2015

* Not yet cleaned within columns: countries, candy_items, in particular for 2015. Waiting to have full df with all three years, to do this in one go.
* Not yet added in additional candy_items with JOY/DESPAIR ratings, stored in `x2015_additional_ratings` (subsetted into `x2015_additional_joy` and `x2015_additional_despair`).
* Any analyses by age or gender will filter out 2015 data because all _NA_ here.
* Note: no MEH ratings in 2015 data.

## 2016 data

Follow 2015 cleaning steps, see what needs changing:

* 1. subset to remove unwanted columns
* 2. clean up included variables --> keep as clean_wide data
* 3. pivot to long format for tidy data --> keep as clean_long data

### 1. subset to remove unwanted columns

Decisions to change or remove columns:

| Column # | Current variable name <type> | Action & reasoning |
| ----- | ----- | ----- |
| 1 | `Timestamp` <dttm> | Convert to `year` <dttm (YYYY)> |
| 2 | `Are you going actually going trick or treating yourself?` <chr> |  Convert to `goes_trick_or_treating` <chr> |
| 3 | `Your gender:` <chr> |  Convert to `gender` <chr> |
| 4 | `How old are you?` <chr> | Convert to `age` <int> |
| 5 | `Which country do you live in?` <chr> |  Convert to `country` <chr> |
| 6 | `Which state, province, county do you live in?` <chr> |  Remove, not needed |
| 7-106 | Candy and other items | Remove non-candy items, as noted below, then make tidy -> `Candy_item` <chr> + `Rating` <chr> |
| 107-108 | Additional JOY and DESPAIR-rated items | Process and include, if time (as per 2015) |
| 109 | `Please leave any witty, snarky or thoughtful remarks or comments regarding your choices.` | remove for now; if time, inspect to see if additional data worth keeping |
| 110-123 | Miscellaneous | Remove, irrelevant |

Decisions on variables to keep/remove:

* Non-candy items to remove:
  * Other food/drink items, not candy: [22] `Chardonnay`, [38] `Healthy fruit`, [49] `Kale smoothie`, [69] `Minibags of chips`, [90] `Spotted Dick`, [104] `White bread`, [105] `Whole wheat anything`
  * Pharmaceuticals: [31] `[Generic Brand Acetaminophen]`, [102] `[Vicodin]`
  * Other items, not food: [12] `Bonkers (the board game)`, [15] `Broken glow stick`, [21] `Cash...`, [26] `Creepy Religious comics...`, [27] `Dental paraphenalia`,
[32] `Glow sticks`, [43] `Hugs...`, [79] `Person of interest...` (DVD)
* Some new items retained as candy (beyond 2015 items):
  * [94] `Sweetums` - from fictional TV series, but online search suggests some candies made under this name at some point, so possible they could have been handed out at Halloween
  * [103] `Whatchamacallit Bars` - a chocolate-based baked item

```{r 2016_step1}
# this code chunk is in cleaning.R script

## step 1: subset to remove unwanted columns
x2016_subset <- x2016 %>% 
  select(1:5,7:11,13,14,16:20,23:25,28:30,33:37,39:42,44:48,50:68,
         70:78,80:89,91:101,103,106) 
    # not yet including 107:109 for additional ratings and comments
# 1259 obs x 89 var
```


### 2. clean up included variables

First, check which age data values will be coerced to NA by converting to numeric (learning from 2015 cleaning steps):

```{r}
x2016_subset %>% 
  mutate(id = c(1:nrow(x2016_subset)), .before = "Timestamp") %>% 
  rename(age_raw = "How old are you?") %>% 
  mutate(age = as.integer(age_raw)) %>% 
  filter(is.na(age)) %>% 
  select(id, age_raw, age)
```
68 rows were coerced to NA. By inspection, none are worth recoding before converting age to numeric.

```{r 2016_step2}
# this code chunk is in cleaning.R script

## step 2: clean up included variables to produce required common df structure: 
# [1]id [2]year [3]age [4]gender [5]country 
# [6]goes_trick_or_treating [7]candy_item [8]rating
x2016_subset_converted <- x2016_subset %>% 
  # make an id column to retain unique identifier for each person
  mutate(id = c(1:nrow(x2016_subset)), .before = "Timestamp") %>% 
  # rename variables
  rename(year = "Timestamp",
         goes_trick_or_treating = "Are you going actually going trick or treating yourself?",
         gender = "Your gender:",
         age = "How old are you?",
         country = "Which country do you live in?"
         ) %>%
  # change format of age and year data
  mutate(age = as.integer(age), # Note: this introduces NAs by coercion
         year = as.numeric(format(year, "%Y")))
```

### 3. pivot to long format for tidy data

```{r 2016_step3}
# this code chunk is in cleaning.R script

## step 3: make long format tidy data
# with one column for candy items 7:90, one column for rating
# expect 1259 x 90 df to become 
# (1259 raters * 84 items) x 8 = 105,756 x 8
x2016_tidy <- x2016_subset_converted %>% 
  pivot_longer(cols = -c(year, id, age, gender, country, goes_trick_or_treating),
               names_to = "candy_item",
               values_to = "rating")
```

### Summary

These steps worked with minimal changes compared to 2015. Note 2016 data includes country and gender data, not yet inspected for cleaning (to do once all years combined).

## 2017 data

Follow 2015+2016 cleaning steps and see what needs changing:

* 1. subset to remove unwanted columns
* 2. clean up included variables --> keep as clean_wide data
* 3. pivot to long format for tidy data --> keep as clean_long data

### 1. subset to remove unwanted columns

Decisions to change or remove columns:

| Column # | Current variable name <type> | Action & reasoning |
| ----- | ----- | ----- |
| 1 | Internal ID | Inspect - either keep or replace with my ID |
| 2 | Q1: GOING OUT? | keep, make consistent |
| 3 | Q2: GENDER | keep, make consistent |
| 4 | Q3: AGE | keep, make consistent |
| 5 | Q4: COUNTRY | keep, make consistent |
| 6 | Q5: STATE, PROVINCE, COUNTY, ETC | remove, not needed |
| 7-109 | Q6 Candy & other items | Inspect to decide which to keep & remove (as below) |
| 110-111 | Q7/8 Additional joy & despair | remove for now; if time, include as additional data |
| 112 | Q9 other comments | remove |
| 113-120 | Irrelevant Qs | remove |

Decisions on variables to keep/remove:

* Non-candy items to remove:
  * Other food/drink items, not candy: [22] `Chardonnay`, [38] `Healthy fruit`, [49] `Kale smoothie`, [70] `Minibags of chips`, [86] `Sandwich... Booberry crunch`, [92] `Spotted Dick`, [107] `White bread`, [108] `Whole wheat anything`
  * Pharmaceuticals: [31] `[Generic Brand Acetaminophen]`, [105] `[Vicodin]`
  * Other items, not food: [12] `Bonkers (the board game)`, [15] `Broken glow stick`, [21] `Cash...`, [26] `Creepy Religious comics...`, [27] `Dental paraphenalia`, [32] `Glow sticks`, [43] `Hugs...`, [69] `Abstained from M&M'ing`, [81] `Real Housewives...` (DVD)


```{r 2017_step1}
# this code chunk is in cleaning.R script

## step 1: subset to remove unwanted columns
x2017_subset <- x2017 %>% 
  select(1:5,7:11,13,14,16:20,23:25,28:30,33:37,39:42,44:48,50:68,
         71:80,82:85,87:91,93:101,103,104,106,109) 
# not yet including 110:112 for additional ratings and comments
# outputs 2460 obs x 88 var
```

#### 2. clean up included variables

First, check which age data values will be coerced to NA by converting to numeric (learning from 2015 cleaning steps):

```{r}
x2017_subset %>% 
  rename(age_raw = "Q3: AGE") %>% 
  select(age_raw) %>% 
  mutate(age = as.integer(age_raw)) %>% 
  summarise(across(.cols = c(age, age_raw),
                   .fns = ~ sum(is.na(.x))))
```

Age_raw has 84 NAs in already; converting to numeric coerces additional 24 NAs. Inspect:

```{r}
# Find coerced NAs in age(int)
x2017_subset %>% 
  rename(age_raw = "Q3: AGE") %>% 
  select(`Internal ID`, age_raw) %>% 
  mutate(age = as.integer(age_raw)) %>% 
  filter(!is.na(age_raw)) %>% 
  filter(is.na(age))
```

Some age data to recode:

| ID | Age_raw | Action |
|----|----|----|
| 90278186 | See question 2 | checking raw data shows "I'd rather not say" - nothing to recode |
| 90280448 | sixty-nine | recode to 69 |
| 90280466 | 46 Halloweens. | Assume means 46, recode |
| 90292907 | 59 on the day after Halloween | recode to 58 |

```{r 2017_step2}
# this code chunk is in cleaning.R script

## step 2: clean up included variables to produce required common df structure: 
# [1]id [2]year [3]age [4]gender [5]country 
# [6]goes_trick_or_treating [7]candy_item [8]rating
x2017_subset_converted <- x2017_subset %>% 
  # rename variables
  rename(goes_trick_or_treating = "Q1: GOING OUT?",
         gender = "Q2: GENDER",
         age = "Q3: AGE",
         country = "Q4: COUNTRY") %>%
  # recode some specific age values before converting to numeric (see above)
  mutate(age = case_when(
    `Internal ID` == 90280448 ~ "69",
    `Internal ID` == 90280466 ~ "46",
    `Internal ID` == 90292907 ~ "58",
    .default = age)) %>%
  # change format of age data
  mutate(age = as.integer(age)) %>% # Note: this introduces NAs by coercion
  # add a year column
  mutate(year = rep(2017, nrow(x2017_subset)), .before = goes_trick_or_treating) %>% 
  # make an id column to retain unique identifier for each person
  mutate(id = c(1:nrow(x2017_subset)), .before = year) %>% 
  mutate(id = (year*10000)+id, .before = year) %>% 
  # remove original id column
  select(-c(`Internal ID`))
# outputs df: 2460 obs. x 89 var (1 more col than subset: id)
```

#### 3. pivot to long format for tidy data

```{r 2017_step3}
# this code chunk is in cleaning.R script

## step 3: make long format tidy data
# with one column for candy items, one column for rating
# expect 2460 x 89 df to become 
# (2460 raters * 83 items) x 8 = 204,180 x 8
x2017_tidy <- x2017_subset_converted %>% 
  pivot_longer(cols = -c(year, id, age, gender, country, goes_trick_or_treating),
               names_to = "candy_item",
               values_to = "rating")
```

## Join data for all 3 years

Join by binding columns: requires columns to match name-wise but not in same order.

```{r cleaning_join}
# Dim to expect:
# sum(nrow(x2015_tidy),nrow(x2016_tidy),nrow(x2017_tidy)) # 753,368 rows x 8 cols

# Bind rows -- this line is in cleaning.R script
candy_ratings_allyears <- bind_rows(x2015_tidy, x2016_tidy, x2017_tidy)
# Dim (actual): 753,368 rows x 8 cols
```


# 3: Cleaning data values in joined data {#clean}

* find missing values, NAs
* clean up country column - need USA, Canada, UK, all other countries
  * note in 2016 there is age data in the country column!
* clean up any other data, e.g. candy item; check ratings are consistent

## Load in joined data

Joined data created in cleaning.R script

```{r, message = FALSE}
candy_ratings <- read_csv("../clean_data/candy_ratings_allyears.csv")
```

Currently rater info is duplicated many times (once per each candy item rated). Collapse the data to look at individual rater info (without all their ratings).

```{r}
candy_raters <- candy_ratings %>% 
  select(id,year,age,gender,country,goes_trick_or_treating) %>% 
  unique()

# dim(candy_raters) # 9348 raters
```

## Standard NAs

Note: all these NAs are not out of the ordinary, they represent unanswered survey questions and/or invalid data (coerced to NA in cleaning script).

```{r}
# check for standard NAs in raters information
candy_raters %>% 
  summarise(across(.cols = everything(),
                   .fns = ~ sum(is.na(.x))))
```

Note there is no gender or country information in raw data for 2015, so instead there are lots of NAs added to these columns from all the 2015 raters.

```{r}
# check for standard NAs in ratings information
candy_ratings %>% 
  select(candy_item, rating) %>% 
  summarise(across(.cols = everything(),
                   .fns = ~ sum(is.na(.x))))
```

NAs in ratings are real: not every candy item was rated by every individual, encoded as NA here.

## Age

```{r}
# check low ages
candy_raters %>% 
  filter(!is.na(age)) %>% 
  filter(age <= 6) %>% 
  arrange(age)
```
These all could be real (e.g. if parent recording a rating for young children) and are very few (relative to size of data). Therefore, filter for age 1+ when analysing by age, and recode country == 1 to NA.

```{r}
# check higher ages
candy_raters %>% 
  filter(!is.na(age)) %>%
  filter(age > 99) %>% 
  arrange(age)
# 21 raters with age 100+
```

The oldest person that ever lived, as far as is verified so far, was 122 years old (source: [wikipedia](https://en.wikipedia.org/wiki/List_of_the_verified_oldest_people)), so include a cut-off for age no greater than 125. 

Do not remove whole rows for the entries that do not match, since people may have included an incorrect age in this data as a way to obfuscate, but still have entered real ratings data.

Instead, filter for age 1-125 when analysing age data.

## Gender

```{r}
candy_raters %>% 
  group_by(gender) %>% 
  summarise(count = n())
```
That looks clean enough.

## Goes trick or treating

```{r}
candy_raters %>% 
  group_by(goes_trick_or_treating) %>% 
  summarise(count = n())
```
That looks clean enough too.

## Candy items

```{r}
# inspect candy_items (cleaning steps below)
candy_ratings %>% 
  group_by(candy_item) %>%
  summarise(count = n())
# start: 182 distinct items
```

Cleaning script for candy_items:
```{r clean_candy}
# this code chunk is included in cleaning.R script

# make temp df to check cleaning progress
candy_ratings_after_item_cleaning <- candy_ratings  %>% 
  # remove unwanted strings to standardise candy items
  mutate(candy_item = str_replace_all(candy_item, "^Q6\\ \\|\\ ", ""),
         candy_item = str_replace_all(candy_item, "^\\[", ""),
         candy_item = str_replace_all(candy_item, "\\]$", "")) %>% 
  # recode Mary Janes == anonymous brown globs
  mutate(candy_item = case_when(
        candy_item %in% c("Anonymous brown globs that come in black and orange wrappers", "Anonymous brown globs that come in black and orange wrappers\t(a.k.a. Mary Janes)") ~ "Mary Janes",
        candy_item == "Bonkers" ~ "Bonkers (the candy)",
        candy_item == "Box’o’ Raisins" ~ "Box'o'Raisins",
        candy_item == "JoyJoy (Mit Iodine!)" ~ "JoyJoy (Mit Iodine)",
        candy_item == "Sweetums (a friend to diabetes)" ~ "Sweetums",
        candy_item == "Tolberone something or other" ~ "Toblerone",
        .default = candy_item)) %>% 
  # make new column with candy item by type (to collapse variants of same candy)
  mutate(candy_item_type = case_when(
    str_detect(.$candy_item, "marties") ~ "Smarties",
    str_detect(.$candy_item, "M\\&M") ~ "M&Ms",
    str_detect(.$candy_item, "Licorice") ~ "Licorice",
    str_detect(.$candy_item, "Jolly Rancher") ~ "Jolly Rancher",
    .default = candy_item
  ))
```

Cleaning steps to make candy items consistent:

Start: 182 distinct items, aiming for ~85 from knowledge of data:

* 2017 data had Q6 | at start of each - remove this string --> 182 items
* note second half have items in [..], remove these --> 103 items
* note "Anonymous brown globs that come in black and orange wrappers\t(a.k.a. Mary Janes)" --> indicates "Anonymous brown globs that come in black and orange wrappers" == "Mary Janes" - recode all these --> 101 items
* recode: Bonkers == Bonkers (the candy) - no way of knowing if Bonkers the board game for 2015 data --> 100 items
* recode: "Box’o’ Raisins" ~ "Box'o'Raisins"--> 99 items
* recode: "JoyJoy (Mit Iodine!)" ~ "JoyJoy (Mit Iodine)" --> 98 items
* recode: "Sweetums (a friend to diabetes)" ~ "Sweetums" --> 97 items
* recode: "Tolberone something or other" ~ "Toblerone" --> typo, same 97 items
* to deal with different versions of same type of candy, make new column `candy_item_type` with major type (for variants of Smarties, M&Ms, Licorice, Jolly Rancher) then can decide which column to analyse --> by type, 86 items.

Candy item cleaning complete --> added to cleaning script.

```{r}
# re-inspect candy_item after cleaning
candy_ratings_after_item_cleaning %>% 
  group_by(candy_item) %>%
  summarise(count = n())

# inspect candy_item_type produced in cleaning
candy_ratings_after_item_cleaning %>% 
  group_by(candy_item_type) %>%
  summarise(count = n())
```

## Rating

```{r}
candy_ratings %>% 
  group_by(rating) %>% 
  summarise(count = n())
```

Data looks clean, contains expected categories, and I expected MEH less than others because no MEH ratings in 2015 data.

## Country

```{r}
# countries before cleaning
candy_raters %>% 
  filter(!is.na(country)) %>% 
  distinct(country)
# starts with 168 distinct values
```

```{r clean_country}
# Note: this code chunk is part of the cleaning.R script

# make vector of all misstypings of USA
USAs <- candy_raters %>% 
  mutate(country = str_to_upper(country)) %>%
  filter(!is.na(country)) %>% 
  distinct(country) %>% 
  arrange(desc(country)) %>% 
  # enter TRUE if country may be USA
  mutate(USA = str_detect(.$country, "^U") | str_detect(.$country, "^THE") | str_detect(.$country, "STAT|USA|TRUMPISTAN|AAAYYYYYY|MERICA|AMERC|MUR|YORK|JERSEY|PITTSBURGH|CAROLINA|CALIFORNIA|ALASKA")) %>% 
  filter(USA == TRUE) %>% 
  # filter out non-USA entries (assume unhinged states is USA)
  mutate(USA = !(str_detect(.$country, "^NOT") | str_detect(.$country, "N\\.|KIN|UK|UD|UAE|U.K.|OLD|CASCADIA|NETHERLANDS"))) %>%
  filter(USA == TRUE) %>%
  select(country) %>% 
  pull() # 55 values

# clean country column
candy_raters_after_country_cleaning <- candy_raters %>%
  mutate(country = str_to_upper(country)) %>% 
  mutate(country = if_else(country == "NOT THE USA OR CANADA", NA_character_, country)) %>% 
  mutate(country = case_when(country %in% USAs ~ "USA", .default = country)) %>% 
  mutate(country = case_when(
    str_detect(.$country, "^UNITED") ~ "UK",
    str_detect(.$country, "UK|U\\.K\\.|ENGLAND|ENDLAND") ~ "UK",
    str_detect(.$country, "\\`$") ~ "CANADA",
    str_detect(.$country, "CAN$") ~ "CANADA",
    str_detect(.$country, "THE\\ NETHERLANDS") ~ "NETHERLANDS",
    str_detect(.$country, "^ESPA") ~ "SPAIN",
    str_detect(.$country, "CASCADIA") ~ "CASCADIA",
    str_detect(.$country, "^[0-9]+") ~ NA_character_,
    str_detect(.$country, "\\ ONE|UD|SUBSCRIBE|CANUCK|SOMEWHERE|\\ ABOVE|NEVERLAND|NARNIA") ~ NA_character_,
    str_detect(.$country, "INSANITY|ANYMORE|GOD|FEAR|EUA|EARTH|DENIAL|CANAE|ATLANTIS|TROPICAL") ~ NA_character_,
    str_detect(.$country, "^A$") ~ NA_character_,
    .default = country)) %>% 
  mutate(country_type = case_when(
    !(country %in% c("UK","US","CANADA", NA_character_)) ~ "Other",
    country == "CANADA" ~ "Canada", # for aesthetics
    .default = country))
```

Cleaning steps to make candy items consistent:

* Start: 168 distinct items, aiming to recode all USA, UK, Canada, and leave the rest (as other countries).
* Make all uppercase --> 138 rows
* Deal with USA:
  * one entry that contains "USA" is "NOT THE USA OR CANADA" so first, recode this to NA_character_ --> 137 rows
  * then recode contains "USA" or "UNITED STATE" or other entries that I assume mean USA/United States - via a vector to catch all cases --> 83 rows
* Deal with UK: 
  * any remaining that contain: "^UNITED", "UK", "U.K."  --> 80 rows
  * include England: "ENGLAND", "ENDLAND" --> 78 rows
* Deal with Canada: only two alternatives "CANADA`" and "CAN" --> 76 rows
* Deal with numbers in the country column (only for 2016 and 2017 data). I assume these are intended as ages. Note: because I cannot combine character and double-type logicals, I have added a cleaning step early in cleaning process for 2016 and 2017 data to update any NA ages with the number in the country column (where present), before age is converted to numeric: ```mutate(age, if_else((str_detect(.$country, "^[0-9]+") & is.na(age)), country, age))```. This updates the age data in the cleaned files, and now I can just remove the numeric entries in the country column --> 65 rows.
* Recode "THE NETHERLANDS" to "NETHERLANDS" --> 64 rows
* Recode "ESPAÑA" to "SPAIN" --> 63 rows
* Recode contains "CASCADIA" to "CASCADIA" --> 62 rows
* Recode nonsense answers to NA_character_:
  * "\\ ONE" picks up:
    * THERE ISN'T ONE FOR OLD MEN
    * THIS ONE
    * ONE OF THE BEST ONES
  * several other strange entries
  --> now 41 rows
* Note some special cases remain:
  * CASCADIA - is North West America (including both Canada and US states)
  * EUROPE - could include UK, but not specific enough as a location
* Make a new column to use with UK/US/Canada/Other where non-UK/US/Canada/NA are encoded as "Other")

Country cleaning complete --> added to cleaning script.

Note: these cleaning steps can be repeated on the full tidy dataset (candy_ratings) because here the country entries are just repeated many times for each individual rating observation - the cleaning steps will catch all the repeats.

```{r}
# re-inspect countries after cleaning
candy_raters_after_country_cleaning %>%
  distinct(country, country_type)
```

# 4: Analysis {#analyse}

Note: all subsequent code is independent from the objects stored in previous code in this notebook. Therefore, the analysis can be run without re-running the cleaning steps above. However, the analysis requires a csv file written at the end of the `data_cleaning_scripts/cleaning.R` script, so ensure you run this first.

```{r}
# read in file written after cleaning as df to analyse for individual ratings
candy_ratings_analysis <- read_csv("../clean_data/candy_ratings_allyears_clean.csv")

# subset df to analyse info about individual raters
candy_raters_analysis <- candy_ratings_analysis %>% 
  select(id,year,age,gender,country,goes_trick_or_treating) %>% 
  unique()
```

## Q1: Total number of candy ratings

_Q1. What is the total number of candy ratings given across the three years. (Number of candy ratings, not the number of raters. Don’t count missing values)_

```{r}
candy_ratings_analysis %>% 
  filter(!is.na(rating)) %>% 
  nrow()
```

Across 2015, 2016 and 2017, a total of **636,754 ratings** were provided.

## Q2+3: Average age by trick-or-treating activity

For these analyses, I have filtered the age data to only include entries in the range 1-125 years.

```{r}
candy_raters_analysis %>% 
  filter(!is.na(age)) %>%  # 8,902 raters provided age data
  filter(age > 0 & age <= 125) %>%  # of which, 8,889 were within reasonable age range (1-125 years)
  group_by(goes_trick_or_treating) %>% 
  summarise(count = n(),
            avg_age = mean(age))
```

_Q2. What was the average age of people who are going out trick or treating?_
Q2: Of the 931 trick-or-treaters who provided valid age data (age 1-125 years), the average age was **35 years**.

_Q3. What was the average age of people who are not going trick or treating?_
Q3: Of the 7,886 raters who did _not_ go out trick-or-treating, the average age was **39 years**.


## Q4: Candy items most-rated for each rating

_Q4. For each of joy, despair and meh, which candy bar received the most of these ratings?_

```{r}
# looking by individual candy_items
candy_ratings_analysis %>% 
  group_by(candy_item, rating) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  ungroup() %>% 
  group_by(rating) %>% 
  slice(1) %>% 
  arrange(desc(count))
```
The individual candy item with the most JOY ratings was **"Any full-sized candy bar"**, with the most "MEH" ratings was **"Lollipops" (1,570 MEH ratings)**, and with the most "DESPAIR" ratings was **"Mary Janes" (10,676 DESPAIR ratings)**.

"Any full-sized candy bar" and "Lollipops" are fairly generic items, so let's look at the top 5 most-rated as JOY and MEH:

```{r}
# most JOY rated candy items
candy_ratings_analysis %>% 
  select(candy_item, rating) %>% 
  filter(rating == "JOY") %>% 
  group_by(candy_item) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  head(5)
```
Here, we find that **Reese's Peanut Butter Cups** are the second-most-rated as JOY, after the generic "Any full-sized candy bar".

```{r}
# most MEH rated candy items
candy_ratings_analysis %>% 
  select(candy_item, rating) %>% 
  filter(rating == "MEH") %>% 
  group_by(candy_item) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  head(5)
```
Here, we find that **Bonkers** is the specific item with the most MEH ratings, after the generic "Any full-sized candy bar" and "Hard Candy" entries.


```{r}
# looking by candy_item_type
candy_ratings_analysis %>% 
  group_by(candy_item_type, rating) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  ungroup() %>% 
  group_by(rating) %>% 
  slice(1) %>% 
  arrange(desc(count))
```

When looking by candy_item_type, M&Ms receive a lot of ratings (when combined across all the different types of M&M), and become most-rated for both JOY and MEH.

## Q5: Starburst DESPAIR

_Q5. How many people rated Starburst as despair?_

```{r}
candy_ratings_analysis %>% 
  filter(candy_item == "Starburst" & rating == "DESPAIR") %>% 
  summarise(count = n()) %>% 
  pull()
```

1,989 people rated Starbust as DESPAIR.

## Q6: Most popular candy by gender

For Qs6-8, count despair as -1, joy as +1, and meh as 0. Here, I calculate the mean rating value as a proxy for popularity.

```{r}
# first make a numeric rating value column to use
candy_ratings_analysis_num <- candy_ratings_analysis %>%
  mutate(rating_num = case_when(
    rating == "JOY" ~ 1,
    rating == "MEH" ~ 0,
    rating == "DESPAIR" ~ -1,
    .default = NA
  ))
# 753,368 obs x 10 var == same dim as candy_ratings_analysis
```

_Q6. What was the most popular candy bar by this rating system for each gender in the dataset?_

```{r}
candy_ratings_analysis_num %>% 
  group_by(gender, candy_item) %>%
  summarise(popularity = mean(rating_num, na.rm = TRUE)) %>%
  arrange(desc(popularity)) %>% 
  ungroup() %>% 
  group_by(gender) %>% 
  slice(1) %>% 
  ungroup()
```

The generic **Any full-sized candy bar** is the most popular regardless of gender.

```{r}
# filter out non-specific candy bar:
candy_ratings_analysis_num %>% 
  filter(candy_item != "Any full-sized candy bar") %>% 
  group_by(gender, candy_item) %>%
  summarise(popularity = mean(rating_num, na.rm = TRUE)) %>%
  arrange(desc(popularity)) %>% 
  ungroup() %>% 
  group_by(gender) %>% 
  slice(1) %>% 
  ungroup()
```

Filtering this out shows that **Reese's Peanut Butter Cups** are the most popular for respondents who identified as male or female.

(Note: It doesn't matter whether I analyse by individual candy items or types of candy item, the results are the same.)

## Q7: Most popular candy by year

_Q7. What was the most popular candy bar in each year? Count despair as -1, joy as +1, and meh as 0._

```{r}
candy_ratings_analysis_num %>% 
  group_by(year, candy_item) %>%
  summarise(popularity = mean(rating_num, na.rm = TRUE)) %>%
  arrange(desc(popularity)) %>% 
  ungroup() %>% 
  group_by(year) %>% 
  slice(1) %>% 
  ungroup()
```

The generic "Any full-sized candy bar" is most popular in every year. 

```{r}
# filter out non-specific candy bar:
candy_ratings_analysis_num %>% 
  filter(candy_item != "Any full-sized candy bar") %>% 
  group_by(year, candy_item) %>%
  summarise(popularity = mean(rating_num, na.rm = TRUE)) %>%
  arrange(desc(popularity)) %>% 
  ungroup() %>% 
  group_by(year) %>% 
  slice(1) %>% 
  ungroup()
```

When I exclude this generic option, Reese's Peanut Butter cups were the most popular item in 2015 and 2017, and Kit Kats in 2016.

(Again, the results are the same whether looking at individual candy items or by candy types.)

## Q8. Most popular candy by country

_Q8. What was the most popular candy bar by this rating for people in US, Canada, UK, and all other countries? Count despair as -1, joy as +1, and meh as 0._

```{r}
candy_ratings_analysis_num %>% 
  group_by(country_type, candy_item_type) %>%
  summarise(popularity = mean(rating_num, na.rm = TRUE)) %>%
  arrange(desc(popularity)) %>% 
  ungroup() %>% 
  group_by(country_type) %>% 
  slice(1) %>% 
  ungroup()
```

For all countries, "any full-sized candy bar" was the most popular. This is generic, so let's look again for something more specific.

```{r}
# Find the most popular candy item after "any full-sized candy bar"
candy_ratings_analysis_num %>% 
  filter(candy_item_type != "Any full-sized candy bar") %>% 
  group_by(country_type, candy_item_type) %>%
  summarise(popularity = mean(rating_num, na.rm = TRUE)) %>%
  arrange(desc(popularity)) %>% 
  ungroup() %>% 
  group_by(country_type) %>% 
  slice(1) %>% 
  ungroup()
```

Here, we find that Reese's Peanut Butter Cups and Kit Kats are the most popular in the USA and Canada, respectively; while Rolos and Lindt Truffles are popular elsewhere in the world.

# 5: Reflections and potential improvements {#reflect}

Once I had prepared 2015 data, it was simple to adapt the same code to prepare 2016 and 2017 data, despite some differences in how these data were encoded (e.g. column names).

This notebook could be self-contained if I run the cleaning script from within the notebook as the first step in the first code chunk in the `Analysis` section (i.e. in clude source(cleaning.R). I could not get this to work yet.

I could also improve the initial data preparation steps. This currently involves subsetting the raw data using column number, which is the least reproducible and readable way. Now that I know the list of candy items that I decide to include in the final dataset (see vector created below), I could instead use this knowledge to filter for only the items in this list, which could then be easily updated (e.g. adding an item to the vector) and/or applied to other years' dataframes. 

```{r}
# create vector of candy item names to include in final data, based on those included currently
candy_items <- candy_ratings_analysis %>% 
  select(candy_item) %>% 
  unique() %>% 
  pull()
```

The new data preparation flow could be:

  * 1: add year and id columns
  * 2: pivot to long (for all columns that include answers to survey questions after the rater information)
  * 3: remove remaining unwanted columns (e.g. State/Province), clean the colnames
  * 4: bind each year's data together
  * 5: filter candy_item for only the values I want to keep (using str_detect(the vector of candy_items as below))
  * 6: clean the data values (candy_item, country)
  
Another way I could improve this would be to use assertive programming to verify that the data looks as it should before proceeding, e.g. that the data types are as expected, that the age data is within a reasonable range (and if not, prompt the user to inspect this first).

A third way to improve would be to include the additional JOY and DESPAIR ratings given in the free text box answers near the end of the survey in each year.

Finally, I could explicitly check for duplicates in the data - e.g. same rater info and ratings, maybe slightly different timestamp.